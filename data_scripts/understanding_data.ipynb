{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is for mainly understanding the data and finding the correlation, standard deviation and other useful information from the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import math\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.genfromtxt('../orig_data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('../orig_data/Y_train.txt', delimiter=None)\n",
    "Xte = np.genfromtxt('../orig_data/X_test.txt', delimiter=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 14)\n",
      "(200000,)\n",
      "(200000, 1)\n",
      "(200000, 15)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "Y = Y.reshape(Y.shape[0],1)\n",
    "print(Y.shape)\n",
    "train_data = np.append(X, Y, 1)\n",
    "print(train_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0 min is: 193.5 max is: 253.0 mean is: 241.601 standard deviation is: 9.138 median:  243.0\n",
      "1405\n",
      "Feature 1 min is: 152.5 max is: 249.0 mean is: 227.377 standard deviation is: 9.624 median:  229.0\n",
      "167\n",
      "Feature 2 min is: 214.25 max is: 252.5 mean is: 241.554 standard deviation is: 5.94 median:  242.45\n",
      "2712\n",
      "Feature 3 min is: 152.5 max is: 252.5 mean is: 232.827 standard deviation is: 9.881 median:  232.98\n",
      "2677\n",
      "Feature 4 min is: 10.0 max is: 31048.0 mean is: 3089.923 standard deviation is: 3956.199 median:  1651.0\n",
      "4331\n",
      "Feature 5 min is: 0.0 max is: 13630.0 mean is: 928.259 standard deviation is: 1755.495 median:  212.0\n",
      "2203\n",
      "Feature 6 min is: 0.0 max is: 9238.0 mean is: 138.094 standard deviation is: 666.297 median:  0.0\n",
      "916\n",
      "Feature 7 min is: 0.0 max is: 125.17 mean is: 3.249 standard deviation is: 2.867 median:  2.317\n",
      "18462\n",
      "Feature 8 min is: 0.876 max is: 19.167 mean is: 6.499 standard deviation is: 2.531 median:  6.146\n",
      "28901\n",
      "Feature 9 min is: 0.0 max is: 13.23 mean is: 2.097 standard deviation is: 2.089 median:  1.646\n",
      "14979\n",
      "Feature 10 min is: 0.0 max is: 66.761 mean is: 4.218 standard deviation is: 2.021 median:  3.68\n",
      "27826\n",
      "Feature 11 min is: 0.0 max is: 73.902 mean is: 2.692 standard deviation is: 1.483 median:  2.337\n",
      "25251\n",
      "Feature 12 min is: 0.99 max is: 975.04 mean is: 10.272 standard deviation is: 20.116 median:  4.067\n",
      "11493\n",
      "Feature 13 min is: -999.9 max is: 797.2 mean is: 5.781 standard deviation is: 58.365 median:  0.0\n",
      "2182\n",
      "Feature 14 min is: 0.0 max is: 1.0 mean is: 0.343 standard deviation is: 0.475 median:  0.0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "min_arr = []\n",
    "max_arr = []\n",
    "mean_arr = []\n",
    "median_arr = []\n",
    "std_dev = []\n",
    "num_features = []\n",
    "for i in range(train_data.shape[1]):\n",
    "    print(\"Feature\",i, \"min is:\",round(min(train_data[:,i]),3), \"max is:\",round(max(train_data[:,i]),3), \n",
    "          \"mean is:\",round(np.mean(train_data[:,i]),3), \"standard deviation is:\",round(np.std(train_data[:,i]),3), \n",
    "          \"median: \", round(np.median(train_data[:,i]),3))\n",
    "    print(len(np.unique(train_data[:,i])))\n",
    "    min_arr.append(round(min(train_data[:,i]),3))\n",
    "    max_arr.append(round(max(train_data[:,i]),3))\n",
    "    mean_arr.append(round(np.mean(train_data[:,i]),3))\n",
    "    median_arr.append(round(np.median(train_data[:,i]),3))\n",
    "    std_dev.append(round(np.std(train_data[:,i]),3))\n",
    "    num_features.append(len(np.unique(train_data[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193.5, 152.5, 214.25, 152.5, 10.0, 0.0, 0.0, 0.0, 0.876, 0.0, 0.0, 0.0, 0.98999999999999999, -999.89999999999998, 0.0]\n",
      "[253.0, 249.0, 252.5, 252.5, 31048.0, 13630.0, 9238.0, 125.17, 19.167000000000002, 13.23, 66.760999999999996, 73.902000000000001, 975.03999999999996, 797.20000000000005, 1.0]\n",
      "[241.601, 227.37700000000001, 241.554, 232.827, 3089.9229999999998, 928.25900000000001, 138.09399999999999, 3.2490000000000001, 6.4989999999999997, 2.097, 4.218, 2.6920000000000002, 10.272, 5.7809999999999997, 0.34300000000000003]\n",
      "[243.0, 229.0, 242.44999999999999, 232.97999999999999, 1651.0, 212.0, 0.0, 2.3170000000000002, 6.1459999999999999, 1.6459999999999999, 3.6800000000000002, 2.3370000000000002, 4.0670000000000002, 0.0, 0.0]\n",
      "[9.1379999999999999, 9.6240000000000006, 5.9400000000000004, 9.8810000000000002, 3956.1990000000001, 1755.4949999999999, 666.29700000000003, 2.867, 2.5310000000000001, 2.089, 2.0209999999999999, 1.4830000000000001, 20.116, 58.365000000000002, 0.47499999999999998]\n",
      "[1405, 167, 2712, 2677, 4331, 2203, 916, 18462, 28901, 14979, 27826, 25251, 11493, 2182, 2]\n"
     ]
    }
   ],
   "source": [
    "print(min_arr)\n",
    "print(max_arr)\n",
    "print(mean_arr)\n",
    "print(median_arr)\n",
    "print(std_dev)\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213.4978\n",
      "200.0\n",
      "222.6\n",
      "211.82\n",
      "45.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.320094\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1562\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(train_data.shape[1]):\n",
    "    print(np.percentile(train_data[:,i], 1))\n",
    "    #print(np.corrcoef(train_data[:,i], train_data[:,14])[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 15)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_100K = train_data[:100000]\n",
    "validation_data_50K = train_data[100000:150000]\n",
    "test_data_50K = train_data[150000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 15)\n",
      "(50000, 15)\n",
      "(50000, 15)\n"
     ]
    }
   ],
   "source": [
    "print(training_data_100K.shape)\n",
    "print(validation_data_50K.shape)\n",
    "print(test_data_50K.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_arr = []\n",
    "max_arr = []\n",
    "mean_arr = []\n",
    "median_arr = []\n",
    "std_dev = []\n",
    "num_features = []\n",
    "for i in range(train_data.shape[1]):\n",
    "    min_arr.append(round(min(training_data_100K[:,i]),3))\n",
    "    max_arr.append(round(max(training_data_100K[:,i]),3))\n",
    "    mean_arr.append(round(np.mean(training_data_100K[:,i]),3))\n",
    "    median_arr.append(round(np.median(training_data_100K[:,i]),3))\n",
    "    std_dev.append(round(np.std(training_data_100K[:,i]),3))\n",
    "    num_features.append(len(np.unique(training_data_100K[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[195.0, 152.5, 214.25, 152.5, 10.0, 0.0, 0.0, 0.0, 0.876, 0.0, 0.0, 0.0, 0.98999999999999999, -999.89999999999998, 0.0]\n",
      "[253.0, 249.0, 252.5, 252.5, 31048.0, 13630.0, 9238.0, 125.17, 19.167000000000002, 13.23, 27.163, 55.366999999999997, 975.03999999999996, 793.39999999999998, 1.0]\n",
      "[241.58799999999999, 227.36099999999999, 241.541, 232.79900000000001, 3085.6889999999999, 927.46299999999997, 139.26900000000001, 3.2429999999999999, 6.5, 2.0990000000000002, 4.2220000000000004, 2.6949999999999998, 10.304, 5.7729999999999997, 0.34300000000000003]\n",
      "[243.0, 229.0, 242.44999999999999, 232.97999999999999, 1648.0, 212.0, 0.0, 2.3220000000000001, 6.1440000000000001, 1.645, 3.6920000000000002, 2.3439999999999999, 4.0789999999999997, 0.0, 0.0]\n",
      "[9.1509999999999998, 9.6319999999999997, 5.9489999999999998, 9.8780000000000001, 3940.8760000000002, 1752.2170000000001, 671.72400000000005, 2.8439999999999999, 2.5299999999999998, 2.0920000000000001, 2.0099999999999998, 1.4730000000000001, 20.404, 58.030999999999999, 0.47499999999999998]\n",
      "[1131, 158, 2666, 2535, 4316, 2194, 899, 15862, 23485, 13083, 22664, 20880, 10541, 1758, 2]\n"
     ]
    }
   ],
   "source": [
    "print(min_arr)\n",
    "print(max_arr)\n",
    "print(mean_arr)\n",
    "print(median_arr)\n",
    "print(std_dev)\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218.0, 203.0, 225.71000000000001, 213.56999999999999, 66.0, 0.0, 0.0, 0.51207999999999998, 2.5663960000000001, 0.0, 1.8325800000000001, 0.96216999999999997, 1.1907000000000001, 0.0, 0.0]\n",
      "[253.0, 242.5, 250.13, 250.12, 13826.0, 6766.0, 2065.0, 11.718999999999999, 13.185, 7.8075000000000001, 9.8717920000000188, 6.4661999999999997, 29.841000000000001, 85.599999999999994, 1.0]\n"
     ]
    }
   ],
   "source": [
    "feature_2_perc = []\n",
    "feature_98_perc = []\n",
    "for i in range(training_data_100K.shape[1]):\n",
    "    feature_2_perc.append(np.percentile(training_data_100K[:,i], 2))\n",
    "    feature_98_perc.append(np.percentile(training_data_100K[:,i], 98))\n",
    "    #print(np.corrcoef(training_data_100K[:,i], training_data_100K[:,14])[0][1])\n",
    "    \n",
    "print(feature_2_perc)\n",
    "print(feature_98_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213.5\n",
      "200.0\n",
      "222.6\n",
      "211.82\n",
      "46.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.3424\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1556\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#for i in range(training_data_100K.shape[1]-1):\n",
    "#    training_data_100K[training_data_100K[:,i] < feature_2_perc[i], i] = feature_2_perc[i]\n",
    "#    training_data_100K[training_data_100K[:,i] > feature_98_perc[i], i] = feature_98_perc[i]\n",
    "    \n",
    "for i in range(training_data_100K.shape[1]):\n",
    "    print(np.percentile(training_data_100K[:,i], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in range(validation_data_50K.shape[1]-1):\n",
    "#    validation_data_50K[validation_data_50K[:,i] < feature_2_perc[i], i] = feature_2_perc[i]\n",
    "#    validation_data_50K[validation_data_50K[:,i] > feature_98_perc[i], i] = feature_98_perc[i]\n",
    "    \n",
    "#for i in range(test_data_50K.shape[1]-1):\n",
    "#    test_data_50K[test_data_50K[:,i] < feature_2_perc[i], i] = feature_2_perc[i]\n",
    "#    test_data_50K[test_data_50K[:,i] > feature_98_perc[i], i] = feature_98_perc[i]\n",
    "\n",
    "#for i in range(Xte.shape[1]):\n",
    "#    Xte[Xte[:,i] < feature_2_perc[i], i] = feature_2_perc[i]\n",
    "#    Xte[Xte[:,i] > feature_98_perc[i], i] = feature_98_perc[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/abhishekjindal/Desktop/UCI_courses/Fall_2017/CS273A/Assignments/hw4/HW4-code/')\n",
    "import mltools as ml\n",
    "training_data_100K_final, params = ml.rescale(training_data_100K[:,:-1])\n",
    "validation_data_50K_final, _ = ml.rescale(validation_data_50K[:,:-1], params)\n",
    "test_data_50K_final, _ = ml.rescale(test_data_50K[:,:-1], params)\n",
    "Xte_final, _ = ml.rescale(Xte, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('X_training_100K.txt', training_data_100K_final, comments='', delimiter=',')\n",
    "np.savetxt('X_validation_50K.txt', validation_data_50K_final, comments='', delimiter=',')\n",
    "np.savetxt('X_test_50K.txt', test_data_50K_final, comments='', delimiter=',')\n",
    "np.savetxt('X_submission_200K.txt', Xte_final, comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 14)\n"
     ]
    }
   ],
   "source": [
    "print(Xte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "Y_training_data_100K = training_data_100K[:,-1]\n",
    "print(Y_training_data_100K.shape)\n",
    "np.savetxt('Y_training_100K.txt', Y_training_data_100K, comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "Y_validation_data_50K = validation_data_50K[:,-1]\n",
    "print(Y_validation_data_50K.shape)\n",
    "np.savetxt('Y_validation_50K.txt', Y_validation_data_50K, comments='', delimiter=',')\n",
    "Y_test_data_50K = test_data_50K[:,-1]\n",
    "print(Y_test_data_50K.shape)\n",
    "np.savetxt('Y_test_50K.txt', Y_test_data_50K, comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data bins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 200000)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-82ec52b64185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_wise_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmin_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_wise_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmax_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_wise_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "col_wise_X= np.transpose(X)\n",
    "num_bins=10\n",
    "print(col_wise_X.shape)\n",
    "for i in xrange(len(X[i])):\n",
    "    min_val=min(col_wise_X[i])\n",
    "    max_val=max(col_wise_X[i])\n",
    "    bin_sz=((max_val-min_val)/num_bins)\n",
    "    bins=[min_val+j*bin_sz for j in xrange(num_bins)]\n",
    "    count=np.zeros((len(bins)+1,2))\n",
    "    print(\"Graph for Feature: \", i+1)\n",
    "    for j in xrange(len(X)):\n",
    "        ndx=int((X[j][i]- min_val)/bin_sz)\n",
    "        count[ndx][0]+= (1 if Y[j]==0 else 0)\n",
    "        count[ndx][1]+= (1 if Y[j]==1 else 0)\n",
    "    print(sum(count))\n",
    "    plt.hist(count,num_bins, normed=1, histtype='bar', color=['b','g'], label=['b','g'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many features like 7, 8, 12-14 are mostly having little result on predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bb2ede5960ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
